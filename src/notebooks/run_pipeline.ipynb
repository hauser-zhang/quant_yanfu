{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline\n",
    "\n",
    "Main entry point. Configure variables below, then run to generate and optionally execute the bash script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "def find_repo_root() -> Path:\n",
    "    cur = Path().resolve()\n",
    "    for _ in range(6):\n",
    "        if (cur / 'README.md').exists() and (cur / 'src').exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    return Path().resolve()\n",
    "\n",
    "PROJECT_ROOT = find_repo_root()\n",
    "RUN_NAME_BASE = \"ML_2\"\n",
    "SPLIT_MODE = \"simple\"  # or \"forward\"\n",
    "LABEL_MODE = \"winsor_csz\"  # raw | winsor_csz | neu_winsor_csz\n",
    "# NOTE: X_WINSORIZE_BY_DATE / X_ZSCORE_BY_DATE apply to FEATURES only (not labels).\n",
    "X_WINSORIZE_BY_DATE = True  # feature winsorization only\n",
    "X_ZSCORE_BY_DATE = True  # feature zscore only\n",
    "Q_LOW = 0.02\n",
    "Q_HIGH = 0.98\n",
    "MIN_N = 50\n",
    "EPS = 1e-12\n",
    "\n",
    "# Data preprocessing toggles\n",
    "DV_LOG1P = True\n",
    "ADD_TIME_FEATURES = True\n",
    "ADD_MARKET_STATE_FEATURES = True\n",
    "ADD_INDUSTRY_STATE_FEATURES = True\n",
    "DUMP_DEBUG_SNAPSHOTS = False\n",
    "DEBUG_N_ROWS = 2000\n",
    "DEBUG_N_FEATURES = 60\n",
    "\n",
    "DATA_ROOT = str(PROJECT_ROOT / \"data\" / \"project_5year\")\n",
    "POSTPROCESS_PIPELINE = \"none\"  # or neutral_then_z / z_then_neutral\n",
    "USE_PRED_Z = False\n",
    "USE_NEUTRALIZE = False \n",
    "# MODELS_TO_RUN = [\"torch_cnn\", \"torch_rnn\", \"torch_lstm\"]  # add: \"torch_cnn\",\"torch_rnn\",\"torch_lstm\",\"torch_gru\" \"lgbm\", \n",
    "MODELS_TO_RUN = [\"lgbm\", \"extra_trees\", \"elasticnet\", \"xgb\", \"torch_mlp\", \"torch_cnn\", \"torch_rnn\", \"torch_lstm\", \"torch_gru\"]  # add: \"torch_cnn\",\"torch_rnn\",\"torch_lstm\",\"torch_gru\" \"lgbm\", \n",
    "# Torch sequence models (cnn/rnn/lstm/gru): only use G_raw_all.\n",
    "# r_i and dv_i are treated as time sequence pairs: (T=20, C=2).\n",
    "# f_i goes through a small MLP branch; industry_/beta/indbeta goes through a linear risk head.\n",
    "\n",
    "# Training-related hyperparameters\n",
    "TORCH_MAX_EPOCHS = 300  # shared default for torch models\n",
    "TORCH_BATCH_SIZE = 1024\n",
    "TORCH_NUM_WORKERS = 16\n",
    "TORCH_LR = 0.003\n",
    "TORCH_SCHEDULER_TYPE = \"plateau_ic\"  # none | plateau_ic | cosine # lr下降太快了！\n",
    "TORCH_EARLY_STOP_PATIENCE = 50\n",
    "TORCH_EARLY_STOP_MIN_DELTA = 0.0\n",
    "TORCH_LOG_EVERY = 5\n",
    "\n",
    "# Model-related hyperparameters\n",
    "MODEL_PARAM_GRID = {\n",
    "    \"ridge\": {\"alpha\": [0.1, 1.0, 10.0]},\n",
    "    \"elasticnet\": {\"alpha\": [0.001, 0.01], \"l1_ratio\": [0.2, 0.5, 0.8]},\n",
    "    \"rf\": {\"n_estimators\": [100, 200, 300], \"max_depth\": [None, 5]},\n",
    "    \"extra_trees\": {\"n_estimators\": [200, 500], \"max_depth\": [None, 10]},\n",
    "    \"lgbm\": {\"num_leaves\": [31, 63, 127], \"learning_rate\": [0.01, 0.05, 0.1], \"n_estimators\": [500]},\n",
    "    \"catboost\": {\"depth\": [6, 8], \"learning_rate\": [0.05], \"iterations\": [500]},\n",
    "    \"xgb\": {\"n_estimators\": [300, 600], \"max_depth\": [4, 6], \"learning_rate\": [0.05]},\n",
    "    # Torch MLP (alpha head) params\n",
    "    \"torch_mlp\": {\"num_layers\": [2], \"hidden_dim\": [512], \"dropout\": [0.1], \"batch_norm\": [True], \"residual\": [True], \"batch_size\": [TORCH_BATCH_SIZE], \"num_workers\": [TORCH_NUM_WORKERS], \"max_epochs\": [TORCH_MAX_EPOCHS], \"log_every\": [TORCH_LOG_EVERY], \"lr\": [TORCH_LR], \"early_stop_patience\": [TORCH_EARLY_STOP_PATIENCE], \"early_stop_min_delta\": [TORCH_EARLY_STOP_MIN_DELTA], \"scheduler_type\": [TORCH_SCHEDULER_TYPE]},\n",
    "    # Torch CNN/RNN: uses only G_raw_all (r_i, dv_i, f_i, industry_, beta, indbeta)\n",
    "    \"torch_cnn\": {\"cnn_channels\": [(512, 512), (1024, 1024)], \"kernel_size\": [3], \"dropout\": [0.1], \"alpha_layers\": [2], \"alpha_hidden_dim\": [512], \"f_layers\": [1], \"f_hidden_dim\": [512], \"batch_size\": [TORCH_BATCH_SIZE], \"num_workers\": [TORCH_NUM_WORKERS], \"max_epochs\": [TORCH_MAX_EPOCHS], \"log_every\": [TORCH_LOG_EVERY], \"lr\": [TORCH_LR], \"early_stop_patience\": [TORCH_EARLY_STOP_PATIENCE], \"early_stop_min_delta\": [TORCH_EARLY_STOP_MIN_DELTA], \"scheduler_type\": [TORCH_SCHEDULER_TYPE], \"residual\": [True]},\n",
    "    \"torch_rnn\": {\"rnn_hidden\": [512], \"rnn_layers\": [2], \"dropout\": [0.1], \"alpha_layers\": [2], \"alpha_hidden_dim\": [512], \"f_layers\": [1], \"f_hidden_dim\": [512], \"batch_size\": [TORCH_BATCH_SIZE // 4], \"num_workers\": [TORCH_NUM_WORKERS], \"max_epochs\": [TORCH_MAX_EPOCHS], \"log_every\": [TORCH_LOG_EVERY], \"lr\": [TORCH_LR], \"early_stop_patience\": [TORCH_EARLY_STOP_PATIENCE], \"early_stop_min_delta\": [TORCH_EARLY_STOP_MIN_DELTA], \"scheduler_type\": [TORCH_SCHEDULER_TYPE], \"residual\": [True]},\n",
    "    \"torch_lstm\": {\"rnn_hidden\": [512], \"rnn_layers\": [2], \"dropout\": [0.1], \"alpha_layers\": [2], \"alpha_hidden_dim\": [512], \"f_layers\": [1], \"f_hidden_dim\": [32], \"batch_size\": [TORCH_BATCH_SIZE // 4], \"num_workers\": [TORCH_NUM_WORKERS], \"max_epochs\": [TORCH_MAX_EPOCHS], \"log_every\": [TORCH_LOG_EVERY], \"lr\": [TORCH_LR], \"early_stop_patience\": [TORCH_EARLY_STOP_PATIENCE], \"early_stop_min_delta\": [TORCH_EARLY_STOP_MIN_DELTA], \"scheduler_type\": [TORCH_SCHEDULER_TYPE], \"residual\": [True]},\n",
    "    \"torch_gru\": {\"rnn_hidden\": [64], \"rnn_layers\": [1], \"dropout\": [0.1], \"alpha_layers\": [2], \"alpha_hidden_dim\": [64], \"f_layers\": [1], \"f_hidden_dim\": [32], \"batch_size\": [TORCH_BATCH_SIZE // 4], \"num_workers\": [TORCH_NUM_WORKERS], \"max_epochs\": [TORCH_MAX_EPOCHS], \"log_every\": [TORCH_LOG_EVERY], \"lr\": [TORCH_LR], \"early_stop_patience\": [TORCH_EARLY_STOP_PATIENCE], \"early_stop_min_delta\": [TORCH_EARLY_STOP_MIN_DELTA], \"scheduler_type\": [TORCH_SCHEDULER_TYPE], \"residual\": [True]},\n",
    "}\n",
    "N_WORKERS = 16\n",
    "DATA_WORKERS = 16  # parallel loading for daily files\n",
    "PREPROCESS_WORKERS = 8  # multiprocessing for preprocessing\n",
    "DO_BUILD_FEATURES = True\n",
    "DO_RUN_TRAINING = True\n",
    "SAVE_PREDS = False\n",
    "USE_FEAT = True\n",
    "GPU_ID = 3  # default A100; set None for CPU\n",
    "SAMPLE_DAYS_PER_YEAR = 0  # set 0 for full data\n",
    "PARALLEL_MODELS = 1\n",
    "PARALLEL_GRID = 2  # grid-search workers per model\n",
    "MAX_EVALS = 0  # random-search cap per model (0=full grid)\n",
    "GRID_SEED = 42\n",
    "N_JOBS_PER_MODEL = 16\n",
    "DEBUG = True  # verbose debug outputs\n",
    "\n",
    "RUN_NAME = f\"{RUN_NAME_BASE}__{SPLIT_MODE}__{LABEL_MODE}__xw{int(X_WINSORIZE_BY_DATE)}_xz{int(X_ZSCORE_BY_DATE)}\"\n",
    "RUN_NAME += f\"__dv{int(DV_LOG1P)}_tf{int(ADD_TIME_FEATURES)}_mkt{int(ADD_MARKET_STATE_FEATURES)}_ind{int(ADD_INDUSTRY_STATE_FEATURES)}\"\n",
    "RUN_NAME += f\"__q{Q_LOW}-{Q_HIGH}_n{MIN_N}__sd{SAMPLE_DAYS_PER_YEAR}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = PROJECT_ROOT / 'res' / 'experiments' / RUN_NAME\n",
    "script_dir = PROJECT_ROOT / 'scripts' / RUN_NAME\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "script_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/data1/hyzhang/Projects/intreviews_2026/quant_yanfu/scripts/ML_2__simple__winsor_csz__xw1_xz1__dv1_tf1_mkt1_ind1__q0.02-0.98_n50__sd0/run_all.sh')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PARAM_GRID = {k: v for k, v in MODEL_PARAM_GRID.items() if k in MODELS_TO_RUN}\n",
    "grid_path = script_dir / \"param_grid.json\"\n",
    "grid_path.write_text(json.dumps(MODEL_PARAM_GRID, indent=2))\n",
    "\n",
    "LOG_PATH = run_dir / \"log.txt\"\n",
    "\n",
    "cmds = []\n",
    "\n",
    "if DO_BUILD_FEATURES:\n",
    "    cmds.append(\n",
    "        f\"python -m src.features.build_features --data_root {DATA_ROOT} --n_workers {N_WORKERS} --run_name {RUN_NAME}\"\n",
    "    )\n",
    "\n",
    "if DO_RUN_TRAINING:\n",
    "    models = \",\".join(MODELS_TO_RUN)\n",
    "    cmd = (\n",
    "        f\"python -m src.train.run_experiment --data_root {DATA_ROOT} --run_name {RUN_NAME} --split_mode {SPLIT_MODE} --models {models} \"\n",
    "        + (\" --use_feat\" if USE_FEAT else \"\")\n",
    "        + (\" --save_preds\" if SAVE_PREDS else \"\")\n",
    "        + (f\" --gpu_id {GPU_ID}\" if GPU_ID is not None else \"\")\n",
    "        + (f\" --sample_days_per_year {SAMPLE_DAYS_PER_YEAR}\" if SAMPLE_DAYS_PER_YEAR else \"\")\n",
    "        + (f\" --parallel_models {PARALLEL_MODELS}\" if PARALLEL_MODELS else \"\")\n",
    "        + (f\" --parallel_grid {PARALLEL_GRID}\" if PARALLEL_GRID else \"\")\n",
    "        + (f\" --max_evals {MAX_EVALS}\" if MAX_EVALS else \"\")\n",
    "        + (f\" --grid_seed {GRID_SEED}\" if GRID_SEED else \"\")\n",
    "        + (f\" --n_jobs {N_JOBS_PER_MODEL}\" if N_JOBS_PER_MODEL else \"\")\n",
    "        + (f\" --data_workers {DATA_WORKERS}\" if DATA_WORKERS else \"\")\n",
    "        + (f\" --preprocess_workers {PREPROCESS_WORKERS}\" if PREPROCESS_WORKERS else \"\")\n",
    "        + (f\" --label_mode {LABEL_MODE}\")\n",
    "        + (f\" --param_grid {grid_path}\")\n",
    "        + (\" --x_winsorize_by_date\" if X_WINSORIZE_BY_DATE else \"\")\n",
    "        + (\" --x_zscore_by_date\" if X_ZSCORE_BY_DATE else \"\")\n",
    "        + (f\" --q_low {Q_LOW} --q_high {Q_HIGH} --min_n {MIN_N} --eps {EPS}\")\n",
    "        + (\" --dv_log1p\" if DV_LOG1P else \" --no-dv-log1p\")\n",
    "        + (\" --add_time_features\" if ADD_TIME_FEATURES else \" --no-add-time-features\")\n",
    "        + (\" --add_market_state_features\" if ADD_MARKET_STATE_FEATURES else \" --no-add-market-state-features\")\n",
    "        + (\" --add_industry_state_features\" if ADD_INDUSTRY_STATE_FEATURES else \" --no-add-industry-state-features\")\n",
    "        + (\" --dump_debug_snapshots\" if DUMP_DEBUG_SNAPSHOTS else \"\")\n",
    "        + (f\" --debug_n_rows {DEBUG_N_ROWS} --debug_n_features {DEBUG_N_FEATURES}\")\n",
    "        + (f\" --postprocess_pipeline {POSTPROCESS_PIPELINE}\")\n",
    "        + (\" --use_pred_z\" if USE_PRED_Z else \"\")\n",
    "        + (\" --use_neutralize\" if USE_NEUTRALIZE else \"\") + (\" --debug\" if DEBUG else \"\")\n",
    "    )\n",
    "    cmds.append(cmd)\n",
    "\n",
    "cmds = [f\"{c} |& tee -a {LOG_PATH}\" for c in cmds]\n",
    "script_path = script_dir / \"run_all.sh\"\n",
    "content = \"#!/usr/bin/env bash\\nset -euo pipefail\\n\" + \"\\n\".join(cmds) + \"\\n\"\n",
    "script_path.write_text(content)\n",
    "script_path.chmod(0o755)\n",
    "script_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: execute the script\n",
    "# subprocess.run([str(script_path)], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results if available\n",
    "import pandas as pd\n",
    "metrics_path = run_dir / 'metrics.csv'\n",
    "if metrics_path.exists():\n",
    "    display(pd.read_csv(metrics_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: None []\n"
     ]
    }
   ],
   "source": [
    "# Cleanup: remove runs without tuning outputs\n",
    "import shutil\n",
    "exp_root = PROJECT_ROOT / 'res' / 'experiments'\n",
    "script_root = PROJECT_ROOT / 'scripts'\n",
    "removed = []\n",
    "for exp_dir in exp_root.iterdir():\n",
    "    if not exp_dir.is_dir():\n",
    "        continue\n",
    "    tuning_dir = exp_dir / 'tuning'\n",
    "    if (not tuning_dir.exists()) or (not any(tuning_dir.iterdir())):\n",
    "        shutil.rmtree(exp_dir)\n",
    "        script_dir = script_root / exp_dir.name\n",
    "        if script_dir.exists():\n",
    "            shutil.rmtree(script_dir)\n",
    "        removed.append(exp_dir.name)\n",
    "print('Removed:' if removed else 'Removed: None', removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
