# 量化项目研究报告

> 目标：使用每只股票当日的日内收益/成交金额序列特征（r_0~r_19, dv_0~dv_19）及慢变基本面特征（f_0~f_9）等，预测未来 1 天个股收益，并以 **daily-weighted-mean IC** 作为唯一评估标准构建与迭代模型。  

---


## 1. 初步数据分析

### 1.1 数据与任务定义

- 数据区间：2016-01-01 至 2020-12-31（日频）。  
- 存储形式：每日一个文件 `YYYY/MM/DD/data_matrix.csv(.gz)`。  
- 样本粒度：每行 = (date, stock_id) 的横截面观测。  
- 预测目标：`y` = 未来 1 天的个股收益（标量）。  
- 权重：`weight` 为每条样本的加权系数。

日内特征含义（以 30min 桶为单位）：
- `r_i`：过去第 (i+1) 到 i 个 30 分钟的收益（例：`r_7` = 240min→210min 的收益）。  
- `dv_i`：过去第 (i+1) 到 i 个 30 分钟的成交金额（交易额）。  
- `f_0~f_9`：慢变、已正态化处理的基本面/风格类特征。  
- `industry`：行业分类（整数；工程里通常 one-hot）。  
- `beta` / `indbeta`：对市场与行业的风险暴露（未正态化；详见 1.2）。

任务性质：
- 是比较典型的 **横截面排序/alpha 预测**问题，使用前一日内的市场时序交易量、个股收益以及基本面信息等特征来预测未来一日的收益。  
- 评价指标按“日”为单位计算横截面相关，最终看跨日平均表现，因此对“可泛化、跨市场状态稳健的信号”要求更高。

---

### 1.2 特征类型与经济学含义

1) **短期价格行为：r_0~r_19**  
反映日内价格路径：  
- 近端收益（r_0、r_1）通常承载短线动量/反转信号；  
- 更远端收益（如 r_10~r_19）更接近“当天更早的走势”，可能与次日延续/修正相关。

2) **流动性与交易强度：dv_0~dv_19**  
交易额序列反映日内活跃度与冲击：  
- 交易额放大往往对应信息到达/资金冲击；  
- 但 dv 分布重尾极强，通常需要 `log1p` 压缩尾部，再做按日标准化，否则模型易被极端值主导。

3) **基本面特征：f_0~f_9**  
反映跨日缓慢变化的公司属性/风格暴露，常用于解释中期收益差异或作为风险控制信息。

4) **行业类别信息：industry（one-hot）**  
行业信息在横截面中通常强相关于收益（行业轮动、宏观敏感度差异）。  
但行业暴露并不等同于 alpha，需要通过中性化或对照实验区分“行业 beta”与“个股特异信号”。

5) **风险暴露：beta / indbeta**  
- `beta`：个股对全市场收益的敏感度（市场风险暴露）。  
- `indbeta`：个股对行业收益的敏感度（行业风险暴露）。  
经济学意义：beta 高的股票在“市场上行/下行”时反应更大；indbeta 类似但针对行业。  
在 alpha 研究中，常通过“中性化”剥离这些系统性暴露，以更聚焦于 residual alpha（详见第 7 章）。

---

### 1.3 权重 weight 的含义与影响

本项目唯一评价标准采用加权相关（权重为 `weight`）。一个可解释的理解是：  
- `weight` 常用于代表样本的“经济重要性/可交易规模/置信度/流动性权重”等。  
- 权重越大，意味着该股票在评估目标中占比越大，模型需要更重视这些样本的排序正确性。

以一个单日样本（2016-01-07 的股票）为例，weight 均值约 1.7 万，最大值约 7.2 万，量级差异明显。这提示：  
- 训练 loss 若按样本权重加权，会更偏向拟合大权重股票；  
- 评估按日做加权相关，也会更强调大权重股票对相关系数的贡献。  
因此后续所有 sanity check、单因子分析、模型评估都必须严格使用 `weight`。

---

### 1.4 缺失情况与数据质量

缺失值是本任务的核心工程难点之一。我们观察到两类缺失模式：

1) **零星缺失**：同一列在少数股票上缺失（可能由停牌、交易异常、数据对齐问题导致）。  
2) **整列缺失（更严重）**：某些日期下，某些 r/dv 桶对几乎所有股票都缺失。

以单日样本（2016-01-07）为例：
- `r_16~r_19` 与 `dv_16~dv_19` 在该日**缺失严重**
- 这些桶在该日无法提供信息；  
- 若在大量日期都如此，继续保留会带来无信息噪声维度，拖慢训练并可能诱发过拟合。

我们因此在工程上采用两阶段策略：
- **统计筛除**：对全样本统计每个 `r_i/dv_i` 的缺失率与“按日整列缺失频率”，若某列长期无效（如缺失率 > 95%），直接从特征中移除，结果如下图所示：  
![](res/experiments/timeForward_raw2__forward__rolling__winsor_csz__raw_only__xw1_xz1_zf0__dv1_tf1_mkt1_ind1__q0.01-0.99_n50__sd0/figures/missingness_top30.png)
大部分输入特征缺失率均较小（<1%）。
- **缺失显式建模**：不移除特征列，对存在缺失的列，采用 `fillna(0)` + 缺失指示/缺失计数特征（可开关）让模型区分“真实 0”与“缺失填 0”。  

---

### 1.5 y 分布与标签版本

原始标签 `y` 代表未来 1 天收益，通常具有：
- 尖峰厚尾（heavy-tail）  
- 不同日期波动水平不同（cross-day volatility heterogeneity）

因此训练与评估会使用标签变换版本（在工程中用 `y_score` 表示“用于建模与评分的一致口径标签”），常见选择包括：
- `winsor_csz`：按日 winsorize 后做横截面 z-score，强调当日相对排序。  
- `neu_winsor_csz`：在 `winsor_csz` 基础上先对行业/风险暴露中性化（回归残差），更接近 residual alpha。  
（详见第 2 章与第 7 章。）

---

### 1.6 单因子 IC sanity check

目的：在复杂模型之前，先验证“输入特征是否存在可预测性线索”，并识别：
- 最有信息的基础特征（如近端动量、交易额冲击等）；  
- 可能只是“暴露类信号”的特征（industry/beta）；  
- 明显无效或噪声很大的特征（长期整列缺失的 r/dv 桶）。

方法定义：对每个输入特征 x，计算其与 `y_score` 的 **daily-weighted-mean IC**：
- 每天计算横截面加权相关 `IC_t(x) = weighted_corr(x_t, y_score_t, w_t)`  
- 再按日权重 `W_t = sum_i w_{t,i}` 做跨日加权平均  
- 同时报告 `IC_std` 与 `IC_IR = mean/std` 作为稳定性度量

IC相关性较高的20个特征如下：
![](res/experiments/timeForward_all__forward__rolling__winsor_csz__all_extended__xw1_xz1_zf0__dv1_tf1_mkt1_ind1__q0.01-0.99_n50__sd0/factor_ic/factor_ic_top20.png)


---

## 2. 数据预处理 & 特征工程

### 2.1 输入特征预处理：dv_log1p、winsorize_by_date、按日标准化

由于 dv 分布重尾，且不同日期横截面尺度不同，输入特征预处理采取以下流程（可通过开关控制）：

1) **dv_log1p**  
对 `dv_0~dv_19` 先做：
`dv <- log1p(max(dv,0))`  
动机：压缩极端尾部，避免模型被少数超大交易额样本支配。

2) **winsorize_by_date**  
对每个日期横截面，按分位截断极端值（如 1%/99%），减少异常点影响。

3) **按日标准化（x_zscore_by_date）**  
默认对 `r_*`、`dv_*`、`ind_*`、`beta/indbeta` 等做按日 z-score；`f_*` 默认不做按日 z-score（可开关 `--zscore_f_features`）。  
动机：`f_*` 已预归一且慢变，重复按日标准化可能破坏跨日可比性；`ind_*` 在日内横截面存在差异，因此纳入按日标准化。

---

### 2.2 标签处理：y_raw / winsor_csz / neu_winsor_csz

为了使训练目标与评分口径一致，我们将“训练标签”和“评分标签”统一在同一 label space（记为 `y_score`）。常用模式：

1) **winsor_csz**  
   - 按日 winsorize（截尾）  
   - 按日做横截面 z-score：`y_csz = (y - mean_t) / std_t`  
   意义：强调当日相对收益排序，弱化跨日波动差异。

2) **neu_winsor_csz（标签中性化，可选）**  
在 `winsor_csz` 前或后，对行业与风险暴露做回归：
   - `y ~  beta*all + indbeta*industry + residual_alpha`  
   取残差作为标签，再做按日标准化（或相反顺序需明确并固定）。  
   - 意义：中性化（neutralization）作为可选的数据处理步骤，用于在“信号含义”层面区分系统性暴露与个股特异超额收益（residual alpha）。在横截面预测中，行业与 `beta/indbeta` 等风险暴露往往能带来较高相关，但其经济学含义更接近系统性风险溢价或行业轮动暴露，未必代表可控的 alpha；因此我们通过按日横截面回归将这些共同成分剥离，使模型更聚焦于个股特异部分。

---

### 2.3 经济学特征构建（示例与解释）

在原始 r/dv 基础上构建多窗口聚合特征，以显式表达常见的经济学信号（动量、反转、波动、流动性冲击）：

1) **动量（Momentum）类**  
   - `mom_30m`：近 30min 收益（通常接近 r_0）  
   - `mom_2h`：近 2 小时累计收益（例如 sum(r_0..r_3)）  
   - `mom_6h`：更长窗口累计收益（视有效 r 桶缺失情况选择）  
   经济学解释：短期趋势延续/信息扩散导致的收益延续效应。

2) **反转（Reversal）类**  
   - `rev_30m`：近端收益的反向项（若完全等价于 -r_0，属于冗余项应默认剔除）  
经济学解释：微观结构噪声、流动性提供导致的短期价格回撤。

3) **波动（Volatility）类**  
   - `vol_2h`：近 2 小时收益波动（std/abs sum 等）  
   经济学解释：波动上升可能反映信息不确定性与风险补偿，也可能代表噪声上升，需要模型学习其方向性。

4) **流动性冲击（Liquidity Shock）类**  
   - `dv_log_sum_2h`：近 2 小时交易额（log1p 后聚合）  
   - `dv_shock`：交易额相对自身历史/当日其他桶的异常程度  
   经济学解释：资金冲击/信息事件导致的交易活跃度异常，可能与次日继续定价相关。

冗余控制：
   - 对明显重复或线性等价特征（如 `ret_last` 与 `r_0` 完全一致，`rev_30m` 与 `-r_0` 等价），默认从输入中移除，避免增加噪声维度与过拟合风险。

---

### 2.4 行业状态特征 ind_*

`ind_*` 为 date×industry 聚合后回填到个股，因此在同一天横截面中因行业不同而不同，能有效影响排序。

示例：
- `ind_r_mean/std`：行业内收益水平/波动  
- `ind_dv_mean/std`：行业内交易活跃度水平/离散度  
经济学解释：行业轮动与行业层面的资金/信息冲击会影响行业内个股次日表现与风险补偿。

---

### 2.5 个股 ID 信息

由于 ID 信息可能吸收“个体固定效应”（流动性、长期风险属性、数据质量模式等），我们将其作为可控增强项，并通过消融/对照实验验证其可泛化性：

- **Torch：id embedding（端到端学习向量表示）**  
  风险：容易记忆个股噪声导致过拟合。  
- **Tabular（LGBM/Sklearn）：id encoding（OOF target/mean encoding）**  
  采用训练集内部 K-fold out-of-fold 方式生成 `id_te`，避免标签泄漏。  

默认策略：关闭 ID 信息，只有在对照实验/最终模型候选中才开启。

---

### 2.6 Missing 信息特征

当采用 `fillna(0)` 时，模型若不知道哪些值是缺失，会把“缺失填 0”当成真实 0，可能引入系统误差。  
因此提供可选 missing 特征：
- `r_missing_cnt`, `dv_missing_cnt`  
- `beta_isna`, `indbeta_isna`, `any_f_missing`, `industry_isna`

经济学解释：缺失往往对应停牌/低流动性/数据对齐失败等状态，可能与次日收益和风险显著相关。  

---

## 3. 模型架构和训练过程

### 3.1 统一训练设置


- 数据切分：本研究采用滚动/扩窗训练（time-forward-rolling），验证与测试窗口随时间前进，模拟真实上线迭代，以保证验证的稳定性。具体而言，设置`FORWARD_TRAIN_MONTHS = 12, FORWARD_VAL_MONTHS = FORWARD_TEST_MONTHS = 3, FORWARD_STEP_MONTHS = 6`。即每次使用12个月数据训练，随后3个月数据作验证集，3个月数据作测试集。以步长6个月后移，直到数据终点，所有轮次中，使用训练数据进行模型训练，验证集合进行超参数调优，最终在独立测试集上进行模型性能评估，取所有轮次平均得分作为模型最终性能评估。
- 唯一指标：**daily-weighted-mean IC**（按日加权相关，再跨日加权平均）

- 输出位置：`res/experiments/{RUN_NAME}/metrics/metrics.csv`

---

### 3.2 机器学习模型

本研究构建的机器学习模型如下：
- ElasticNet（线性，强正则）
- ExtraTrees（非线性树集成）
- LightGBM / XG-boost（梯度提升树）

所有机器学习模型训练时，以所有输入特征作为输入（industry这类分类变量采取one-hot编码形式）。

---

### 3.3 深度学习模型

深度学习模型采用 **Sequence + Tabular Hybrid** 架构，将日内序列与慢变特征分支建模，并显式拆分 alpha 与 risk：

- **序列模块（sequence backbone）**：从 `(r_i, dv_i)` 的长度为 20 的短序列中提取局部模式（近端动量、反转、成交额冲击等）。该模块使用 **MLP / 1D-CNN(含 dilated conv/TCN) / RNN / LSTM / GRU** 等架构。
- **基本面模块（fundamentals MLP）**：对 `f_*` 基本面特征做 MLP 表征后与序列 embedding 拼接，用于增强慢变信息。
- **聚合金融特征模块（可选）**：对在原始 r/dv 基础上构建多窗口聚合特征特征做 MLP 表征后与上述特征拼接。
- **风险模块（risk head）**：以 `industry` one-hot 与 `beta/indbeta` 为输入的线性头，建模市场/行业暴露项；最终预测为 `pred = alpha + risk`，提升可解释性并减轻 alpha 分支拟合压力。
- **ID 模块（可选）**：当开启 `use_id_embedding` 时，对 `id` 使用 embedding（配合 embedding dropout）引入个体固定效应信息；该信息源易过拟合，因此必须在 forward rolling 下通过消融与对照实验验证其泛化收益。

模型使用MSE-loss和AdamW优化器进行训练，添加BatchNorm、DropOut以及Early-Stopping等以缓解过拟合问题。

---

### 3.4 模型性能评估

不同模型性能比较如下图所示：
![](res/experiments/DL__simple__winsor_csz__xw1_xz1__dv1_tf1_mkt1_ind1__q0.02-0.98_n50__sd0/plots/model_comparison.png)
- 总体而言，使用MLP为backbone的深度学习模型模型性能最优，在测试集上具有最高的平均IC（0.11），并且具有较低的跨轮次波动。
- 各个模型都存在比较严重的过拟合现象（如下图所示），模型性能总体较差，由于时间原因和机器计算能力有限暂时还未很好解决。
![](res/experiments/timeForward_all__forward__rolling__winsor_csz__all_extended__xw1_xz1_zf0__dv1_tf1_mkt1_ind1__q0.01-0.99_n50__sd0/tuning/torch_loss/torch_lstm_fold0_alpha_hidden_dim-128_alpha_layers-2_batch_size-128_best_metric-ic_dropout-0.2_ea_9b0d0e93.png)
- 由于所有模型架构均存在过拟合问题，推断原因为金融特征信息中存在较大波动和噪音，模型难以从数据中学习到可泛化的特征模式，后续可能需要考虑对原始数据进行去噪和进一步细致清洗，排除其中低质量的训练数据。

---

## 5. 特征重要性分析 & 消融实验

### 5.1 重要性方法

- **树模型（LightGBM / ExtraTrees）**：使用 *gain importance* 作为快速筛查，并辅以 *permutation importance*（在验证集对单列置乱，观察 valid daily IC 的下降）作为与最终指标更一致的边际贡献度量。  
- **深度模型（MLP/CNN/RNN）**：以 *permutation importance* 为主（输入列或特征组置乱），强调“破坏该信息源后，排序能力下降多少”。

---

### 5.2 消融实验结果

对于训练得到的最优的模型架构，本研究随后采用消融实验方式来解析特征重要性以检验各个特征的平均收益与稳定性，发现其中对于股票收益预测具有重要意义的经济学特征（基本面特征/动量类/反转类/流动性冲击/行业状态等），从而能够有助于构建更好的投资策略。总体而言，我发现：
- 对训练目标y按日期进行归一化和中性化对模型性能有小幅提升。
- 添加动量、波动等聚合经济学特征对于模型性能有小幅提升。
- 添加个股id特征对模型性能有小幅提升，但在某些场景下会加剧过拟合问题。

> TODO：消融实验的代码已完成，但由于模型过拟合问题尚未解决，该部分结果暂时还比较初步，我后续会继续完善调整模型后把这部分构建完成。

---

### 6.1 当前阶段最稳健方案

在本研究的统一评估口径（**daily-weighted-mean IC**）与 **time-forward rolling** 主评估框架下，我们将“稳健性”定义为：在多个前推轮次中取得**更高的平均测试 IC、较低的跨轮次波动（std）、以及更可解释的信号来源**。

当前阶段最稳健的方案为使用原本输入特征+构建的聚合经济学特征，并对输入特征做归一化、预测目标y做归一化和中性化后，使用MLP作为基座的深度学习模型进行预测。

### 6.2 思路总结

- 本研究首先通过 **单因子 IC sanity check** 验证信号存在性、识别长期缺失或信息含量不足的特征列，并将其作为后续特征工程与数据清洗的依据，从而避免在噪声维度上浪费模型容量。  
- 在横截面次日收益预测中，**经济学工程特征**（多窗口动量/反转、波动、交易额冲击等）与 **行业状态信息（ind_*）** 往往构成主要的可解释增益来源：前者刻画短期价格与成交结构，后者反映行业层面的共同因子与轮动环境。  
- **ID 与 Missing 信息**属于高风险增强项：它们可能提升拟合能力，但同样更容易引入“个体记忆”或“数据质量代理”导致的过拟合。
- 所有的额外特征信息，都需要通过消融实验分析以检验其平均收益与稳定性，只有在跨轮次一致增益的情况下才应作为默认配置启用。 
- 对于金融数据的显著非平稳性（regime shift），单次年份切分可能产生误导；采用 **forward rolling** 能更接近真实上线迭代过程，并提供对模型泛化能力更稳健的衡量标准。
- 本研究构建了特异性的深度神经网络架构，对于不同数据类型的特征采用异构神经网络模块进行特征提取，并聚合各类特征信息进行最终预测。

### 6.3 下一步改进方向
 
- **解决模型过拟合问题**：主要还是从数据清洗和去噪方面进行改进。首先考虑丢弃某些存在较大特征缺失比例的个股、日期的数据，但由于统计分析结果显示数据缺失比例不足1%，这块能够获得的提高估计有限；其次由于dv、r等时序数据时间点较少、粒度较粗，可能存在较大波动，考虑低通滤波等方式对信号进行平滑降噪处理。  
- **跨日滞后信息扩展**：引入更丰富的 lag features（例如过去 N 日的聚合动量/波动/成交冲击），以缓解“仅用当日信息预测次日”的信号衰减问题，并与序列模块形成互补。
